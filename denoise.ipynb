{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "  # %tensorflow_version only exists in Colab.\n",
    "  %tensorflow_version 2.x\n",
    "except Exception:\n",
    "  pass\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5/5 [==============================] - 3s 304ms/step - loss: 0.0637\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 2s 308ms/step - loss: 0.0605\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 1s 279ms/step - loss: 0.0563\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 1s 271ms/step - loss: 0.0501\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 2s 313ms/step - loss: 0.0439\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 2s 398ms/step - loss: 0.0360\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 1s 276ms/step - loss: 0.0247\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 2s 287ms/step - loss: 0.0140\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 2s 292ms/step - loss: 0.0114\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 1s 280ms/step - loss: 0.0091\n",
      "5/5 [==============================] - 1s 75ms/step\n",
      "Denoised images saved to 'denoised_images'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Load images from dataset\n",
    "def load_images_from_folder(folder, target_size=(256, 256)):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img_path = os.path.join(folder, filename)\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if img is not None:\n",
    "            img = cv2.resize(img, target_size)  # Resize images to a uniform size\n",
    "            images.append(img)\n",
    "    return images\n",
    "\n",
    "# Add noise to images\n",
    "def add_noise(images, noise_factor=0.5):\n",
    "    noisy_images = []\n",
    "    for img in images:\n",
    "        noise = np.random.normal(loc=0.0, scale=noise_factor, size=img.shape)\n",
    "        noisy_img = np.clip(img + noise, 0., 255.)\n",
    "        noisy_images.append(noisy_img.astype(np.uint8))\n",
    "    return noisy_images\n",
    "\n",
    "# Build a simple Denoising Autoencoder\n",
    "def build_denoising_autoencoder(input_shape):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Input(shape=input_shape))\n",
    "    model.add(layers.Conv2D(16, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.MaxPooling2D((2, 2), padding='same'))\n",
    "    model.add(layers.Conv2D(8, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.MaxPooling2D((2, 2), padding='same'))\n",
    "    model.add(layers.Conv2D(8, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.UpSampling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(16, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.UpSampling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same'))\n",
    "    return model\n",
    "\n",
    "# Denoise images\n",
    "def denoise_images(model, noisy_images):\n",
    "    noisy_images = np.array(noisy_images) / 255.0  # Normalize\n",
    "    denoised_images = model.predict(noisy_images)\n",
    "    return (denoised_images * 255).astype(np.uint8)\n",
    "\n",
    "# Save images to folder\n",
    "def save_images(images, folder):\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "    for i, img in enumerate(images):\n",
    "        cv2.imwrite(os.path.join(folder, f'denoised_image_{i}.png'), img)\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "    # Paths\n",
    "    dataset_path = 'covid'\n",
    "    save_path = 'denoised_images'\n",
    "\n",
    "    # Load images\n",
    "    images = load_images_from_folder(dataset_path)\n",
    "\n",
    "    # Add noise\n",
    "    noisy_images = add_noise(images)\n",
    "\n",
    "    # Build and compile the denoising autoencoder model\n",
    "    input_shape = (images[0].shape[0], images[0].shape[1], 1)  # Assuming images are grayscale\n",
    "    autoencoder = build_denoising_autoencoder(input_shape)\n",
    "    autoencoder.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "    # Train the autoencoder (for demo purposes; adjust epochs and batch size as necessary)\n",
    "    # Note: This is a simple example. For best results, you should train on a larger dataset.\n",
    "    x_train = np.array(noisy_images) / 255.0  # Normalize\n",
    "    x_train_clean = np.array(images) / 255.0  # Normalize\n",
    "    autoencoder.fit(x_train, x_train_clean, epochs=10, batch_size=32)\n",
    "\n",
    "    # Denoise images\n",
    "    denoised_images = denoise_images(autoencoder, noisy_images)\n",
    "\n",
    "    # Save denoised images\n",
    "    save_images(denoised_images, save_path)\n",
    "\n",
    "    print(f\"Denoised images saved to '{save_path}'.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:From c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Load images from dataset\n",
    "def load_images_from_folder(folder, target_size=(256, 256)):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img_path = os.path.join(folder, filename)\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if img is not None:\n",
    "            img = cv2.resize(img, target_size)  # Resize images to a uniform size\n",
    "            images.append(img)\n",
    "    return images\n",
    "\n",
    "# Add noise to images\n",
    "def add_noise(images, noise_factor=0.5):\n",
    "    noisy_images = []\n",
    "    for img in images:\n",
    "        noise = np.random.normal(loc=0.0, scale=noise_factor, size=img.shape)\n",
    "        noisy_img = np.clip(img + noise, 0., 255.)\n",
    "        noisy_images.append(noisy_img.astype(np.uint8))\n",
    "    return noisy_images\n",
    "\n",
    "# Build U-Net model\n",
    "def build_unet(input_shape):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "\n",
    "    # Encoder\n",
    "    c1 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    c1 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(c1)\n",
    "    p1 = layers.MaxPooling2D((2, 2))(c1)\n",
    "\n",
    "    c2 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(p1)\n",
    "    c2 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(c2)\n",
    "    p2 = layers.MaxPooling2D((2, 2))(c2)\n",
    "\n",
    "    c3 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(p2)\n",
    "    c3 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(c3)\n",
    "    p3 = layers.MaxPooling2D((2, 2))(c3)\n",
    "\n",
    "    # Bottleneck\n",
    "    c4 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(p3)\n",
    "    c4 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(c4)\n",
    "\n",
    "    # Decoder\n",
    "    u5 = layers.UpSampling2D((2, 2))(c4)\n",
    "    u5 = layers.concatenate([u5, c3])\n",
    "    c5 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(u5)\n",
    "    c5 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(c5)\n",
    "\n",
    "    u6 = layers.UpSampling2D((2, 2))(c5)\n",
    "    u6 = layers.concatenate([u6, c2])\n",
    "    c6 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(u6)\n",
    "    c6 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(c6)\n",
    "\n",
    "    u7 = layers.UpSampling2D((2, 2))(c6)\n",
    "    u7 = layers.concatenate([u7, c1])\n",
    "    c7 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(u7)\n",
    "    c7 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(c7)\n",
    "\n",
    "    outputs = layers.Conv2D(1, (1, 1), activation='sigmoid')(c7)\n",
    "\n",
    "    model = models.Model(inputs=[inputs], outputs=[outputs])\n",
    "    return model\n",
    "\n",
    "# Denoise images\n",
    "def denoise_images(model, noisy_images):\n",
    "    noisy_images = np.array(noisy_images) / 255.0  # Normalize\n",
    "    denoised_images = model.predict(noisy_images)\n",
    "    return (denoised_images * 255).astype(np.uint8)\n",
    "\n",
    "# Save images to folder\n",
    "def save_images(images, folder):\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "    for i, img in enumerate(images):\n",
    "        cv2.imwrite(os.path.join(folder, f'denoised_image_{i}.png'), img)\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "    # Paths\n",
    "    dataset_path = 'covid'\n",
    "    save_path = 'denoised_images_unet'\n",
    "\n",
    "    # Load images\n",
    "    images = load_images_from_folder(dataset_path)\n",
    "\n",
    "    # Add noise\n",
    "    noisy_images = add_noise(images)\n",
    "\n",
    "    # Build and compile the U-Net model\n",
    "    input_shape = (images[0].shape[0], images[0].shape[1], 1)  # Assuming images are grayscale\n",
    "    unet_model = build_unet(input_shape)\n",
    "    unet_model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "    # Train the U-Net (for demo purposes; adjust epochs and batch size as necessary)\n",
    "    x_train = np.array(noisy_images) / 255.0  # Normalize\n",
    "    x_train_clean = np.array(images) / 255.0  # Normalize\n",
    "    unet_model.fit(x_train, x_train_clean, epochs=50, batch_size=16)\n",
    "\n",
    "    # Denoise images\n",
    "    denoised_images = denoise_images(unet_model, noisy_images)\n",
    "\n",
    "    # Save denoised images\n",
    "    save_images(denoised_images, save_path)\n",
    "\n",
    "    print(f\"Denoised images saved to '{save_path}'.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
